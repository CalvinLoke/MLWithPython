{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pyodc #for sql server connections\n",
    "import pandas\n",
    "import numpy \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:\n",
      "        time  year  month_no  total_traffic  total_passengers  total_mail\n",
      "0    1980-01  1980         1           6501            566879         619\n",
      "1    1980-02  1980         2           6112            552263         593\n",
      "2    1980-03  1980         3           6391            597644         642\n",
      "3    1980-04  1980         4           6247            561218         642\n",
      "4    1980-05  1980         5           6301            587003         646\n",
      "..       ...   ...       ...            ...               ...         ...\n",
      "482  2020-03  2020         3          16223           1649662        2558\n",
      "483  2020-04  2020         4           3865             25189         931\n",
      "484  2020-05  2020         5           4472             24504        1633\n",
      "485  2020-06  2020         6           4779             48241        2496\n",
      "486  2020-07  2020         7           5247             85981        3054\n",
      "\n",
      "[487 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the data \n",
    "csv_file = r'C:\\Users\\HexagonRig 2\\Documents\\GitHub\\MLWithPython\\Sample Data\\airport_data.csv'\n",
    "raw_dataframe = pandas.read_csv(csv_file)\n",
    "\n",
    "print(\"Dataframe:\")\n",
    "print(raw_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     month_no  total_traffic\n",
      "257         6          15092\n",
      "132         1           8615\n",
      "252         1          15253\n",
      "207         4          14138\n",
      "92          9           6320\n",
      "..        ...            ...\n",
      "108         1           6952\n",
      "311        12          17916\n",
      "291         4          14768\n",
      "113         6           7209\n",
      "69         10           6137\n",
      "\n",
      "[482 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Defining the dependent and independent variables\n",
    "independent_variables = ['month_no','total_traffic']\n",
    "dependent_variable = ['total_passengers']\n",
    "\n",
    "independent_dataset = raw_dataframe[independent_variables]\n",
    "dependent_dataset = raw_dataframe[dependent_variable]\n",
    "\n",
    "# Further splitting dataset into training and testing subsets\n",
    "test_ratio=0.01\n",
    "indp_train_set, indp_test_set, dep_train_set, dep_test_set = train_test_split(independent_dataset, \n",
    "                                                                              dependent_dataset, \n",
    "                                                                              test_size=test_ratio)\n",
    "\n",
    "print(indp_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create regression object and train model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_model.fit(indp_train_set, dep_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3157385.58781068],\n",
       "       [4453054.61797732],\n",
       "       [4702391.42426204],\n",
       "       [ 702308.71327726],\n",
       "       [ 763092.8646663 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "linear_predictions = linear_model.predict(indp_test_set)\n",
    "linear_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed error 26710207858.4099\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions\n",
    "linear_mse = mean_squared_error(linear_predictions, dep_test_set)\n",
    "print(\"Computed error\", linear_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\xe6\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x1asklearn.linear_model._base\\x94\\x8c\\x10LinearRegression\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\rfit_intercept\\x94\\x88\\x8c\\tnormalize\\x94\\x89\\x8c\\x06copy_X\\x94\\x88\\x8c\\x06n_jobs\\x94N\\x8c\\x0en_features_in_\\x94K\\x02\\x8c\\x05coef_\\x94\\x8c\\x15numpy.core.multiarray\\x94\\x8c\\x0c_reconstruct\\x94\\x93\\x94\\x8c\\x05numpy\\x94\\x8c\\x07ndarray\\x94\\x93\\x94K\\x00\\x85\\x94C\\x01b\\x94\\x87\\x94R\\x94(K\\x01K\\x01K\\x02\\x86\\x94h\\x0e\\x8c\\x05dtype\\x94\\x93\\x94\\x8c\\x02f8\\x94\\x89\\x88\\x87\\x94R\\x94(K\\x03\\x8c\\x01<\\x94NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00t\\x94b\\x89C\\x10\\x18\\x96$+\\xb8\\\\\\xca@r\\x87\\tc\\xd1\\xa4e@\\x94t\\x94b\\x8c\\t_residues\\x94h\\rh\\x10K\\x00\\x85\\x94h\\x12\\x87\\x94R\\x94(K\\x01K\\x01\\x85\\x94h\\x1a\\x89C\\x08plaQ\\xf9\\xfe\\xadB\\x94t\\x94b\\x8c\\x05rank_\\x94K\\x02\\x8c\\tsingular_\\x94h\\rh\\x10K\\x00\\x85\\x94h\\x12\\x87\\x94R\\x94(K\\x01K\\x02\\x85\\x94h\\x1a\\x89C\\x10S:\\x00\\x85m\\xe2\\x06A\\xed:\\xe2\\xf0\\x05\\xf8R@\\x94t\\x94b\\x8c\\nintercept_\\x94h\\rh\\x10K\\x00\\x85\\x94h\\x12\\x87\\x94R\\x94(K\\x01K\\x01\\x85\\x94h\\x1a\\x89C\\x08`\\xfb&@\\xec7\\x15\\xc1\\x94t\\x94b\\x8c\\x10_sklearn_version\\x94\\x8c\\x060.23.2\\x94ub.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = pickle.dumps(linear_model)\n",
    "trained_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
